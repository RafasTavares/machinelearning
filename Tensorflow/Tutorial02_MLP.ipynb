{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Tutorial 2 - MLP\n",
    "\n",
    "O objetivo final deste tutorial é mostrar como podemos implementar uma MLP (*Multilayer Perceptron*) no Tensorflow. No entanto, para ajudar a entender um pouco como funciona o Tensorflow vamos implementar primeiro uma rede mais simples (a Perceptron, que possui uma camada apenas) e, em seguida, iremos implementar a MLP. \n",
    "\n",
    "A implementção é baseada no Cap. 3 do livro do [Redes Neurais Artificiais Para Engenharia e Ciências Aplicadas](https://artliber.com.br/index.php?route=product/product&product_id=77) do professor Ivan Nunes e no tutorial [Elementary Neural Networks with TensorFlow](https://medium.com/@jaschaephraim/elementary-neural-networks-with-tensorflow-c2593ad3d60b#.40xi9im8s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Rede Perceptron\n",
    "\n",
    "A rede perceptron é a forma mais simples de configuração de uma rede neural artificial. A arquitetura da rede se aproxima daquela que foi apresentada no problema de regressão linear do Tutorial 1. \n",
    "\n",
    "A imagem a seguir mostra a arquitetura da rede perceptron. \n",
    "\n",
    "<img src=\"https://www.embarcados.com.br/wp-content/uploads/2016/09/Perceptron-01.png\" width=\"50%\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rede é construída a partir de $n$ sinais de entrada e uma única saída, já que ela possui somente um neurônio. Mais detalhes de como a rede perceptron funciona, pode ser encontrado [neste video](https://www.youtube.com/watch?v=pkAKtL9FvFI):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A rede perceptron é utilizada em problemas que são ditos linearmente separáveis. Entende-se por esse tipo de problema aqueles que são compostos por dados que podem ser separados por uma função linear. Para isso, vamos criar um conjunto de dados que possuem tal característica. Como o propósito é só mostrar o funcionamento da rede, vamos criar um conjunto de dados sem nenhum próposito específico.\n",
    "\n",
    "Os dados de entrada são constituídos de várias instâncias contendo duas variáveis cada ($x_1$ e $x_2$) e cada instância é classificada em 0 ou 1. Sendo assim, a tarefa da rede é aprender um modelo que seja capaz de separar estas duas classes. O código a seguir cria os dados e os exibem em um gráfico. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIoFRcYuIBEbFLSISmP8HbzfX/YHWuwUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1044402e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Criando os dados de entrada (x = features e y = classes)\n",
    "x_train = np.array([[2., 2.],[1., 3.],[2., 3.],[5., 3.],[7., 3.],[2., 4.],[3., 4.],[6., 4.],\n",
    "                    [1., 5.],[2., .5],[5., 5.],[4., 6.],[6., 6.],[5., 7.]],dtype=\"float32\")\n",
    "y_train = np.array([[0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.]], dtype=\"float32\")\n",
    "\n",
    "#Mostrando o Gráfico\n",
    "A = x_train[:, 0]\n",
    "B = x_train[:, 1]\n",
    "\n",
    "colormap = np.array(['r', 'k'])\n",
    "\n",
    "# Plot the original data\n",
    "plt.scatter(A, B, c=colormap[[0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1]], s=40)\n",
    "\n",
    "plt.ylim([0,8]) # Limit the y axis size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "O próximo passo é criar a seguinte rede no Tensorflow.\n",
    "\n",
    "<img src=\"https://www.embarcados.com.br/wp-content/uploads/2016/09/Perceptron-01.png\" width=\"50%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Observe que a rede é composta por um conjunto de sinais de entrada ($x_{train} = [x_1, x_2, ..., x_n]$). Cada sinal é poderado por um peso w, dado por $weights = [w_1, w_2, ..., w_3]$ e somado por um limiar de ativação ($\\theta$). Sendo assim, o neurônio é representado pela seguinte operação: \n",
    "\n",
    "$u = \\sum_{i=1}^{n}{w_i*x_i} + bias$\n",
    "\n",
    "O valor inicial do $bias$ é dado por $-\\theta$. Neste exemplo, $\\theta = 1$.\n",
    "\n",
    "O valor de $u$ é entrada para uma função de ativação ($g$) gerando o sinal de saída $y=g(u)$.\n",
    "\n",
    "Nesse exemplo, a função de ativação é dada por: \n",
    "\n",
    "$g(u) = 1$, se $u >= 0$\n",
    "\n",
    "$g(u) = 0$, se $u < 0$\n",
    "\n",
    "O código a seguir implementa esse modelo. Mais detalhes são dados nos comentários do código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# imports necessários\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Função de ativação\n",
    "def output(u):\n",
    "    is_greater = tf.greater(u, 0)\n",
    "    as_float = tf.to_float(is_greater)\n",
    "    return as_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Criação do array que representa o limiar. O limiar é inicializado com -1. Neste caso, o limiar representa um vetor \n",
    "14x1, ou seja, é atribuído um limiar para cada valor de entrada (no caso, 14).\n",
    "'''\n",
    "limiar_array = np.ones([14,1], dtype=\"float32\")*(-1)\n",
    "limiar = tf.Variable(limiar_array, name=\"limiar\")\n",
    "\n",
    "'''\n",
    "Criação da variável com pesos. Como estamos trabalhando com dois valores de entrada por instância, os pesos são \n",
    "instanciados por um vetor 2x1\n",
    "'''\n",
    "weights = tf.Variable(tf.random_normal([2,1]), name=\"pesos\")\n",
    "\n",
    "# Placeholders para feed dos dados de entrada e saída\n",
    "X = tf.placeholder(tf.float32, x_train.shape)\n",
    "Y = tf.placeholder(tf.float32, y_train.shape)\n",
    "\n",
    "# Modelo criado \n",
    "u = tf.matmul(x_train,weights) + limiar\n",
    "\n",
    "# Aplicação da função de ativação\n",
    "output_value = output(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Modelo criado. A próxima etapa é definir como nosso modelo será treinado. \n",
    "\n",
    "Este problema é uma tarefa de classificação. Cada instância vai ser classificada como 0 ou 1 de acordo com a classe que pertence. Sendo assim, o primeiro passo é comparar a saída com a classificação da base de treinamento. Para isso foi calculado o erro da seguinte forma:\n",
    "\n",
    "$mse = \\sum_{i = 1}^{N}{(y_i - output_i)^2}$\n",
    "\n",
    "O objetivo do treinamento é reduzir esse erro. Isso é dado pelo código a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "error = tf.subtract(y_train.T, output_value)\n",
    "mse = tf.reduce_sum(tf.square(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Um outro passo do treinamento é a atualização dos valores dos pesos e do limiar. Esses parâmetros são atualizados segundo fórmula descrita no livro do Ivan Nunes. \n",
    "\n",
    "$w_{i}^{atual} = w_{i}^{anterior} + \\eta (d^{(k)} - y).x_{i}^{(k)}$\n",
    "\n",
    "$\\theta_{i}^{atual} = \\theta_{i}^{anterior} + \\eta (d^{(k)} - y).(-1)$\n",
    "\n",
    "onde:\n",
    "\n",
    "$d^{(k)}$ é o valor desejado e $y$, o valor de saída produzido pela perceptron. Essa diferença é representada pelo que chamamos de erro no código anterior. $\\eta$ é uma constante que define a taxa de aprendizagem da rede (no código, vamos referenciar $\\eta$ por *learning_rate*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "delta_w = tf.matmul(x_train, learning_rate*error, transpose_a=True)\n",
    "delta_limiar = tf.matmul(limiar, learning_rate*error, transpose_a=True)\n",
    "\n",
    "train_w = tf.assign(weights, tf.add(weights, delta_w))\n",
    "train_limiar = tf.assign(limiar, tf.add(limiar, delta_limiar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Uma vez que criamos o modelo, vamos executar as operações para treina-lo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights\n",
      "[[ 0.24686992]\n",
      " [ 0.03673019]]\n",
      "Limiar -0.894671\n"
     ]
    }
   ],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init_op)\n",
    "\n",
    "for step in range(5000):\n",
    "    _, _, a, b, c = sess.run([train_w, train_limiar, mse, weights, limiar], feed_dict={X: x_train, Y: y_train})\n",
    "    \n",
    "print(\"Weights\")\n",
    "print(b)\n",
    "print(\"Limiar\", c[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "O código a seguir apenas cria a função determinada pelos pesos e limiar achados pela rede e plota essa reta no gráfico dos dados mostrado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIpIwKm4RkYT5//hIZhCz+XpnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cf869e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graphic display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "A = x_train[:, 0]\n",
    "B = x_train[:, 1]\n",
    "\n",
    "colormap = np.array(['r', 'k'])\n",
    "\n",
    "# Plot the original data\n",
    "plt.scatter(A, B, c=colormap[[0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1]], s=40)\n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "\n",
    "# Calc the hyperplane (decision boundary)\n",
    "ymin, ymax = plt.ylim()\n",
    "w = b\n",
    "a = -w[0] / w[1]\n",
    "xx = np.linspace(ymin, ymax)\n",
    "yy = a * xx - (c[0,0]) / w[1]\n",
    " \n",
    "# Plot the hyperplane\n",
    "plt.plot(xx,yy, 'k-')\n",
    "plt.ylim([0,8]) # Limit the y axis size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Multilayer Perceptron\n",
    "\n",
    "Uma rede perceptron multicamadas (*Multilayer Perceptron - MLP*) é caracterizada pela presença de pelo menos uma camada intermediária (escondida ou *hidden layer*) de neurônios, situada entre a camada de entrada e a respectiva camada neural de saída. Sendo assim, as MLP possuem pelo menos duas camadas de nurônios, o quais estarão distribuídos entre as camadas intermediárias e a camada de saída. \n",
    "\n",
    "A figura a seguir ilustra este modelo.\n",
    "\n",
    "<img src=\"https://elogeel.files.wordpress.com/2010/05/050510_1627_multilayerp1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Detalhes deste modelo podem ser encontrados no [capítulo 6](http://www.deeplearningbook.org/contents/mlp.html) do [Deep Learning Book](http://www.deeplearningbook.org). Uma outra boa referência é o livro [Redes Neurais Artificiais Para Engenharia e Ciências Aplicadas](https://artliber.com.br/index.php?route=product/product&product_id=77) do professor Ivan Nunes. O tema é abordado no capítulo 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Para mostrar este modelo vamos utilizar o exemplo disponível em [neste link](http://www.jessicayung.com/explaining-tensorflow-code-for-a-multilayer-perceptron/) com a base do MNIST para treinar o modelo criado.\n",
    "\n",
    "Antes de começar a entrar em detalhes da rede, vamos baixar a base do MNIST que será utilizada. O MNIST é um dataset de dígitos escritos a mão. A tarefa consiste em dada uma imagem que representa um dígito escrito à mão classifica-la de acordo com o dígito que foi escrito. Detalhes da base podem ser encontrados [neste link](http://yann.lecun.com/exdb/mnist/). Por ser uma base bastante utilizada, a API do tensorflow já possui a base em um pacote do framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting dataset/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting dataset/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting dataset/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Carregando a base. Se a base não existir a pasta \"dataset/MNIST\" será criada e a base salva nesta pasta.\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"dataset/MNIST\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Cada imagem do dataset possui o tamanho de 28x28 e representa um dígito escrito à mão. A imagem a seguir ilustra uma instância da base:\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/MNIST-Matrix.png\" width=\"70%\" />\n",
    "\n",
    "As imagens vão ser transformadas em um vetor de 784 posições ($28*28$). A entrada da rede são vários vetores deste tipo. Cada vetor vai representar uma imagem. A saída da rede é definida por um vetor de 10 posições, onde cada posição representa uma possível classe do dígito (a base do MNIST trabalha com dígitos de 0 a 9).\n",
    "\n",
    "Se considerarmos que a base de treinamento possui 55000 imagens, as imagens a seguir representam a entrada e saída da rede, respectivamente:\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/mnist-train-xs.png\" width=\"50%\" />\n",
    "<img src=\"https://www.tensorflow.org/images/mnist-train-ys.png\" width=\"50%\"/>\n",
    "\n",
    "A diferença desta representação para o modelo que será implementado aqui é que o nosso modelo será alimentado por *batch*. Uma breve explicação do que é *batch* no tensorflow pode ser encontrado [neste link](http://stackoverflow.com/questions/41175401/what-is-a-batch-in-tensorflow). Vamos utilizar um batch de 100. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Explicações dadas, vamos para o modelo que será implementado.\n",
    "\n",
    "Jessica Yung em seu tutorial [Explaining TensorFlow code for a Multilayer Perceptron](http://www.jessicayung.com/explaining-tensorflow-code-for-a-multilayer-perceptron/) faz uma imagem bem representativa do modelo que será implementado: \n",
    "\n",
    "<img src=\"http://i0.wp.com/www.jessicayung.com/wp-content/uploads/2016/12/multilayer-perceptron-drawing.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Uma questão importante no entendimento (e, consequentemente, na implementação) de qualquer modelo de rede neural é entender as dimensões dos dados ao passar por cada camada. A imagem anterior deixa isso bem claro. Por isso, vamos analisar camada por camada para que possamos entender como essas dimensões são modificadas. Na imagem, h1 e h2 são a quantidade de neurônios nas camadas intermediárias. A quantidade de neurônios de uma camada é que indica a dimensão da saída daquela camada. Outra informação importante é o tamanho do *batch* (já explicado anteriormente).\n",
    "\n",
    "Com o batch igual a 100, a rede está recebendo como entrada uma matriz de 100x784, onde 784 é quantidade de pixel de cada imagem. Sendo assim, cada linha dessa matriz representa uma imagem da base de treinamento. Isso é passado para a primeira camada, onde será aplicada a seguinte operação $xW_1 + b_1$ onde, $W_1$ são os pesos de entrada e $b_1$, o *bias*. A imagem a seguir detalha esta operação juntamente com suas dimensões: \n",
    "\n",
    "<img src=\"http://adolfo.data2learning.com/ludiico/images/mlp_dimensions1.png\" width=\"70%\" />\n",
    "\n",
    "A saída da primeira camada é uma matriz 100x256, ou seja, 100 que representa a quantidade de instâncias que foram passadas na entrada e 256, a quantidade de neurônios. Ou seja, cada neurônio processou cada imagem e deu como resultado uma representação própria da entrada poderada pela operação definida. Ao resultado será aplicada uma função de ativação do tipo *RELU* (acesse o [tutorial da Jessica Yung](http://www.jessicayung.com/explaining-tensorflow-code-for-a-multilayer-perceptron/) para ver detalhes do funcionamento deste tipo de função).\n",
    "\n",
    "A entrada da segunda rede é uma matriz 100x256 (saída da camada anterior). As operações e dimensões da segunda camada são detalhadas na imagem a seguir:\n",
    "\n",
    "<img src=\"http://adolfo.data2learning.com/ludiico/images/mlp_dimensions2.png\" width=\"70%\" />\n",
    "\n",
    "Assim, como na primeira camada, a saída é uma matriz 100x256 que será aplicada uma função de atividação do tipo *RELU*. A camada de saída recebe os dados da segunda e gera como saída uma vetor que represente as 10 classes. Nesse caso, a saída será de 100x10, por conta do *batch*. Em outras palavras, estamos gerando um vetor que pesa cada possível classe para cada uma das 100 instâncias passadas como entrada. A imagem ilustra as operações e dimensões da camada de saída.\n",
    "\n",
    "<img src=\"http://adolfo.data2learning.com/ludiico/images/mlp_dimensions3.png\" width=\"70%\" />\n",
    "\n",
    "À saída da rede é aplicada a função Softmax que transforma os valores dos vetores em probabilidades. A posição que possuir o maior valor de probabilidade representa a classe à qual o dígito pertence. \n",
    "\n",
    "Uma rápida explicação de como funciona a softmax pode ser encontrada [neste vídeo](https://www.youtube.com/watch?v=G8eNWzxOgqE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Explicado o modelo, vamos para o código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports necessários\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Definição de parâmetros\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "\n",
    "#Parâmetros da rede\n",
    "n_hidden_1 = 256 # Quantidade de features da primeira camada escondida \n",
    "n_hidden_2 = 256 # Quantidade de features da segunda camada escondida\n",
    "n_input = 784 # Dados de entrada no MNIST (28 * 28 = 784 (quantidade de pixels da imagem))\n",
    "n_classes = 10 # Número total de classes no MNIST (dígitos de 0-9)\n",
    "\n",
    "# Instanciação dos Input do Grafo no Tensorflow \n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_input]) # Irá armazenar os dados de entrada\n",
    "y = tf.placeholder(tf.float32, [None, n_classes]) #Irá armazenar os dados de saída"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "O modelo é implementado dentro da função *multilayer_perceptron*. Na função criamos cada camada de acordo com os dados passados. É muito importante que as dimensões das variáveis passadas tenham sido definidas corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    \n",
    "    # Primeira camada como função de ativação RELU\n",
    "    \n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Segunda camada com funç!ao de ativação RELU\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    #Camada de Saída\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    \n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Os pesos e bias utilizados serão armazenados em dois dicionários: weights e biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Construindo o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Uma vez que o modelo foi criado, podemos treina-lo. O primeiro passo é definir como vai ser calculado o custo da solução e, em seguida, o método que será utilizado para otimizar o modelo. Três métodos são importantes nesta etapa:\n",
    "\n",
    "* [tf.nn.sofmax_cross_entropy_with_logits](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits)\n",
    "* [tf.reduce_mean](https://www.tensorflow.org/api_docs/python/tf/reduce_mean)\n",
    "* [tf.train.AdamOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer)\n",
    "\n",
    "Detalhes destes métodos podem ser encontrados nos links de cada método. Basicamente, a rede será executada e à saída será aplicada a função softmax para transformar a saída em um vetor de probabilidades. A posição do vetor com maior valor de probabilidade corresponde à classe que a entrada é classificada. Esse resultado é comparado com o resultado esperado em *y* (aprendizado supervisionado) e o custo é calculado. O treinamento será executado com o objetivo de minimizar este custo, ou seja, reduzir a taxa de erro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "O código a seguir executa a etapa de treinamento. Detalhes são dados ao decorrer do código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 157.725429967\n",
      "Epoch: 0002 cost= 40.376680419\n",
      "Epoch: 0003 cost= 25.320531252\n",
      "Epoch: 0004 cost= 17.790744989\n",
      "Epoch: 0005 cost= 12.857540343\n",
      "Epoch: 0006 cost= 9.480761866\n",
      "Epoch: 0007 cost= 7.152568298\n",
      "Epoch: 0008 cost= 5.300936262\n",
      "Epoch: 0009 cost= 3.905300876\n",
      "Epoch: 0010 cost= 2.940291073\n",
      "Epoch: 0011 cost= 2.288513719\n",
      "Epoch: 0012 cost= 1.727777079\n",
      "Epoch: 0013 cost= 1.293939837\n",
      "Epoch: 0014 cost= 0.945999347\n",
      "Epoch: 0015 cost= 0.827342668\n",
      "Fim do treinamento\n",
      "Acurácia: 0.9416\n"
     ]
    }
   ],
   "source": [
    "# Inicializa as variáveis\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Executa o grafo que representa o modelo construído\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    '''\n",
    "    O ciclo de treinamento é chamado de épocas. Em cada época uma quantidade de dados de entrada (batch) é passada\n",
    "    como entrada para a rede. Ao final de cada época, os parâmetros são atualizados de acordo com o treinamento e novos\n",
    "    dados são dados como entrada.\n",
    "    '''\n",
    "    for epoch in range(training_epochs):\n",
    "        \n",
    "        avg_cost = 0. #Armazena a média do custo calculado\n",
    "        \n",
    "        total_batch = int(mnist.train.num_examples/batch_size) # Define o total de épocas: total da base / # batch\n",
    "        \n",
    "        # Loop por cada batch\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # Executa as operações de otimização dos parâmetros (backprop) and custo (retorna o valor de erro)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "            # Calcula a média do erro\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "            \n",
    "    print(\"Fim do treinamento\")\n",
    "    \n",
    "    # Testa o modelo\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "    # Calcula a acurácia\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Acurácia:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Base do noMNIST\n",
    "\n",
    "A tarefa resolvida anteriormente é relativamente simples, já que a base é bem simples e já foi pré-processada com um próposito bem específico. Pensando nisso é que foi criada uma outra base (**noMNIST**) para o mesmo propósito: classificar dígitos, neste caso dígitos de A-Z. Apessar de parecer com o clássico dataset do MNIST, ele envolve uma tarefa mais complicada e os dados estão \"menos limpos\" do que os dados do [MNIST](http://yann.lecun.com/exdb/mnist/). Para mais detalhes, acesse o link: http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html.\n",
    "\n",
    "O primeiro passo é baixar o dataset. Detalhes de como baixa-lo estão disponíveis em: \n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/1_notmnist.ipynb \n",
    "\n",
    "Neste tutorial, assumimos que o dataset já foi baixado na pasta **dataset/**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports necessários\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "#Carrega a base de dados \n",
    "pickle_file = 'dataset/notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Formata os dados para as dimensões apropriadas (784)\n",
    "\n",
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "    # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Vamos utilizar o mesmo método definido anteriormente: **multilayer_perceptron** que recebe como parâmetro os dados de entrada e as variáveis para armazenar os bias e weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "train_dataset = train_dataset[:10000, :]\n",
    "train_labels = train_labels[:10000]\n",
    "\n",
    "new_pred = multilayer_perceptron(train_dataset, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=new_pred, labels=train_labels))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O passo seguinte é treinar o modelo. Observe que diferente do exemplo anterior, neste exemplo vamos trabalhar com a base de treinamento para treinar os dados, a base de validação para testar o modelo ao longo das iterações e ao final testa-lo na base de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 459.844535675\n",
      "\tAcurácia Treinamento: 0.7454\n",
      "\tAcurácia Validação: 0.6934\n",
      "Epoch: 0002 cost= 131.960025024\n",
      "\tAcurácia Treinamento: 0.8222\n",
      "\tAcurácia Validação: 0.7173\n",
      "Epoch: 0003 cost= 64.530110779\n",
      "\tAcurácia Treinamento: 0.8878\n",
      "\tAcurácia Validação: 0.7241\n",
      "Epoch: 0004 cost= 29.856194401\n",
      "\tAcurácia Treinamento: 0.9324\n",
      "\tAcurácia Validação: 0.7197\n",
      "Epoch: 0005 cost= 12.424535551\n",
      "\tAcurácia Treinamento: 0.9677\n",
      "\tAcurácia Validação: 0.7165\n",
      "Epoch: 0006 cost= 4.536465459\n",
      "\tAcurácia Treinamento: 0.9837\n",
      "\tAcurácia Validação: 0.7184\n",
      "Epoch: 0007 cost= 1.587553128\n",
      "\tAcurácia Treinamento: 0.9657\n",
      "\tAcurácia Validação: 0.7192\n",
      "Epoch: 0008 cost= 0.659993879\n",
      "\tAcurácia Treinamento: 0.9959\n",
      "\tAcurácia Validação: 0.7192\n",
      "Epoch: 0009 cost= 0.337804031\n",
      "\tAcurácia Treinamento: 0.9956\n",
      "\tAcurácia Validação: 0.721\n",
      "Epoch: 0010 cost= 0.166149430\n",
      "\tAcurácia Treinamento: 0.9965\n",
      "\tAcurácia Validação: 0.7228\n",
      "Epoch: 0011 cost= 0.229731394\n",
      "\tAcurácia Treinamento: 0.9973\n",
      "\tAcurácia Validação: 0.7228\n",
      "Epoch: 0012 cost= 0.163499728\n",
      "\tAcurácia Treinamento: 0.9961\n",
      "\tAcurácia Validação: 0.7232\n",
      "Epoch: 0013 cost= 0.148778478\n",
      "\tAcurácia Treinamento: 0.996\n",
      "\tAcurácia Validação: 0.7242\n",
      "Epoch: 0014 cost= 0.156884601\n",
      "\tAcurácia Treinamento: 0.9864\n",
      "\tAcurácia Validação: 0.7242\n",
      "Epoch: 0015 cost= 0.184444492\n",
      "\tAcurácia Treinamento: 0.9977\n",
      "\tAcurácia Validação: 0.7252\n",
      "Epoch: 0016 cost= 0.132651188\n",
      "\tAcurácia Treinamento: 0.9981\n",
      "\tAcurácia Validação: 0.7242\n",
      "Epoch: 0017 cost= 0.152578590\n",
      "\tAcurácia Treinamento: 0.9965\n",
      "\tAcurácia Validação: 0.7265\n",
      "Epoch: 0018 cost= 0.196217427\n",
      "\tAcurácia Treinamento: 0.9983\n",
      "\tAcurácia Validação: 0.7252\n",
      "Epoch: 0019 cost= 0.207342000\n",
      "\tAcurácia Treinamento: 0.9985\n",
      "\tAcurácia Validação: 0.7258\n",
      "Epoch: 0020 cost= 0.238043206\n",
      "\tAcurácia Treinamento: 0.9984\n",
      "\tAcurácia Validação: 0.7265\n",
      "Epoch: 0021 cost= 0.145109498\n",
      "\tAcurácia Treinamento: 0.9983\n",
      "\tAcurácia Validação: 0.727\n",
      "Epoch: 0022 cost= 0.232290360\n",
      "\tAcurácia Treinamento: 0.9979\n",
      "\tAcurácia Validação: 0.7266\n",
      "Epoch: 0023 cost= 0.200632530\n",
      "\tAcurácia Treinamento: 0.9978\n",
      "\tAcurácia Validação: 0.7267\n",
      "Epoch: 0024 cost= 0.189921766\n",
      "\tAcurácia Treinamento: 0.9937\n",
      "\tAcurácia Validação: 0.729\n",
      "Epoch: 0025 cost= 0.260261539\n",
      "\tAcurácia Treinamento: 0.9983\n",
      "\tAcurácia Validação: 0.7291\n",
      "Epoch: 0026 cost= 0.252652875\n",
      "\tAcurácia Treinamento: 0.9978\n",
      "\tAcurácia Validação: 0.7272\n",
      "Epoch: 0027 cost= 0.166147781\n",
      "\tAcurácia Treinamento: 0.998\n",
      "\tAcurácia Validação: 0.7267\n",
      "Epoch: 0028 cost= 0.248801760\n",
      "\tAcurácia Treinamento: 0.997\n",
      "\tAcurácia Validação: 0.7274\n",
      "Epoch: 0029 cost= 0.215698629\n",
      "\tAcurácia Treinamento: 0.996\n",
      "\tAcurácia Validação: 0.7308\n",
      "Epoch: 0030 cost= 0.286964614\n",
      "\tAcurácia Treinamento: 0.9985\n",
      "\tAcurácia Validação: 0.7306\n",
      "Fim do treinamento\n",
      "Acurácia: 0.806\n"
     ]
    }
   ],
   "source": [
    "# Inicializa as variáveis\n",
    "\n",
    "training_epochs = 30\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Executa o grafo que representa o modelo construído\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    '''\n",
    "    O ciclo de treinamento é chamado de épocas. Em cada época uma quantidade de dados de entrada (batch) é passada\n",
    "    como entrada para a rede. Ao final de cada época, os parâmetros são atualizados de acordo com o treinamento e novos\n",
    "    dados são dados como entrada.\n",
    "    '''\n",
    "    for epoch in range(training_epochs):\n",
    "        \n",
    "        avg_cost = 0. #Armazena a média do custo calculado\n",
    "        \n",
    "        total_batch = int(train_dataset.shape[0]/batch_size) # Define o total de épocas: total da base / # batch\n",
    "        \n",
    "        # Loop por cada batch\n",
    "        for i in range(total_batch):\n",
    "            \n",
    "            offset = (i * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            \n",
    "            batch_x = train_dataset[offset:(offset+batch_size), :]\n",
    "            batch_y = train_labels[offset:(offset+batch_size), :]\n",
    "            \n",
    "            # Executa as operações de otimização dos parâmetros (backprop) and custo (retorna o valor de erro)\n",
    "            _, c, prediction = sess.run([optimizer, cost, new_pred], feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "            # Calcula a média do erro\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "            \n",
    "            # Acurácia de Treinamento\n",
    "            correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(train_labels, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            print(\"\\tAcurácia Treinamento:\", accuracy.eval({x: train_dataset, y: train_labels}))\n",
    "            \n",
    "            # Acurácia de Validação\n",
    "            \n",
    "            valid_prediction = multilayer_perceptron(valid_dataset, weights, biases)\n",
    "            correct_valid_prediction = tf.equal(tf.argmax(valid_prediction, 1), tf.argmax(valid_labels, 1))\n",
    "            accuracy_valid = tf.reduce_mean(tf.cast(correct_valid_prediction, \"float\"))\n",
    "            print(\"\\tAcurácia Validação:\", accuracy_valid.eval({x: valid_dataset, y: valid_labels}))\n",
    "            \n",
    "            \n",
    "    print(\"Fim do treinamento\")\n",
    "    \n",
    "    # Testa o modelo\n",
    "    test_prediction = multilayer_perceptron(test_dataset, weights, biases)\n",
    "    correct_test_prediction = tf.equal(tf.argmax(test_prediction, 1), tf.argmax(test_labels, 1))\n",
    "    accuracy_test = tf.reduce_mean(tf.cast(correct_test_prediction, \"float\"))\n",
    "    print(\"Acurácia:\", accuracy_test.eval({x: test_dataset, y: test_labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}